================================================================================
PRANAY - SYSTEM ARCHITECTURE AT CONCEPTUAL LEVEL
================================================================================

DOCUMENT: ChemAI System Architecture Design
Date: February 2, 2026

================================================================================
SYSTEM OVERVIEW
================================================================================

ChemAI is an end-to-end AI system for autonomous drug discovery combining:
  • Multi-agent orchestration
  • Machine learning predictions
  • Knowledge graph reasoning
  • Autonomous feedback loops
  • Explainable AI

Design Philosophy:
  1. Modularity: Each component can be improved independently
  2. Autonomy: System can run without human intervention
  3. Causality: Reasoning based on mechanisms, not just patterns
  4. Explainability: Every prediction is justifiable
  5. Scalability: Can handle 10M+ molecules and proteins

================================================================================
ARCHITECTURAL LAYERS
================================================================================

Layer 1: DATA LAYER
-----------------
Sources:
  • Chemical databases (ChEMBL, ZINC, QM9)
  • Protein databases (UniProt, PDB)
  • Bioactivity measurements (IC50, pIC50)
  • Toxicity alerts (PAINS, BRENK)
  • Literature (PubMed, patents)
  • Pathway databases (KEGG, Reactome)

Processing:
  ✓ Data cleaning and standardization
  ✓ SMILES canonicalization
  ✓ Duplicate removal
  ✓ Feature engineering
  ✓ Statistical validation

Output: Clean, standardized molecular and biological data


Layer 2: KNOWLEDGE REPRESENTATION LAYER
-----------------
Knowledge Graph:
  Nodes:
    • Molecules (50k+)
    • Proteins/Targets (10k+)
    • Diseases (1k+)
    • Pathways (100+)
    • Toxicity Alerts (100+)
    • Reaction Steps (1k+)
  
  Edges:
    • molecule --[TARGETS]--> protein (with pIC50 score)
    • protein --[INVOLVED_IN]--> pathway
    • protein --[ASSOCIATED_WITH]--> disease
    • molecule --[HAS_TOXICITY]--> alert (with risk score)
    • molecule --[SIMILAR_TO]--> molecule (with similarity score)
    • molecule --[DERIVED_FROM]--> molecule (parent-child)

  Properties:
    • Nodes: ID, name, description, source, confidence, timestamp
    • Edges: weight, score, evidence, publication, confidence

Graph Features:
  ✓ 200k+ relationships
  ✓ Multi-type entities and edges
  ✓ Temporal tracking
  ✓ Confidence scoring
  ✓ Indexed for fast querying


Layer 3: FEATURE REPRESENTATION LAYER
-----------------
For each molecule:
  • Morgan Fingerprints (2048 bits) - chemical similarity
  • RDKit Descriptors (40+) - molecular properties
  • Graph Embeddings (256 dim) - learned representations
  • ECFP/FCFP (circular fingerprints) - local chemical features
  • Protein Descriptors (for targets)
  • Pathway Embeddings (for context)

For each protein:
  • Sequence Embeddings (from ProtBERT)
  • 3D Structure (when available)
  • Domain Information
  • Phylogenetic Position
  • Associated Pathways

Embedding Spaces:
  ✓ Chemical space (molecules near similar molecules)
  ✓ Target space (proteins grouped by function)
  ✓ Disease space (diseases with similar pathways)
  ✓ Activity space (structures with similar bioactivity)


Layer 4: PREDICTION LAYER (Machine Learning Models)
-----------------
Models (Trained & Ready):

  Model 1: BIOACTIVITY PREDICTOR
    Input: Morgan fingerprint (2048 bits)
    Output: pIC50 (predicted potency)
    Architecture: Random Forest Regressor
    Performance: R² = 0.85 on test set
    Uncertainty: Yes (ensemble-based)

  Model 2: PROPERTY PREDICTOR
    Input: Morgan fingerprint
    Output: 7 properties
      - Molecular Weight
      - LogP (lipophilicity)
      - H-Bond Acceptors
      - H-Bond Donors
      - Polar Surface Area
      - Rotatable Bonds
      - QED (drug-likeness score)
    Architecture: Random Forest (per property)
    Performance: R² = 0.90+ per property

  Model 3: TOXICITY PREDICTOR
    Input: Morgan fingerprint
    Output: Toxicity risk + structural alerts
    Architecture: Classifier + alert matching
    Performance: Accuracy = 0.92

  Model 4: DRUG-LIKENESS PREDICTOR
    Input: Morgan fingerprint
    Output: QED score + Lipinski classification
    Architecture: Regression + Rule-based
    Performance: R² = 0.88 for QED

  Model 5: GRAPH NEURAL NETWORK (GNN) - NEW
    Input: Molecular graph (atoms, bonds)
    Output: Learned representation
    Architecture: Graph attention layers
    Use: Feature extraction, similarity learning

Scoring Function:
  Total Score = w1*bioactivity + w2*druglikeness + w3*safety + w4*novelty
              = 0.4*pIC50 + 0.3*QED + 0.2*toxicity_score + 0.1*diversity


Layer 5: REASONING LAYER
-----------------
Path-Based Reasoning:
  • Find paths in KG: molecule → protein → pathway → disease
  • Explain: "This molecule targets protein X which is in pathway Y associated with disease Z"
  • Strength: Based on edge confidence scores

Similarity-Based Reasoning:
  • Find similar molecules with known activity
  • Reasoning: "This molecule is 95% similar to compound with pIC50=7.2"
  • Confidence: Based on similarity threshold

Causal Reasoning (NEW):
  • Identify causal chains: Structure feature → binding → bioactivity
  • Reasoning: "Aromatic ring at position X increases binding by 2.3 fold"
  • Source: Literature + experimental data

Counterfactual Analysis (NEW):
  • Generate hypothetical modifications
  • Reasoning: "If we add a methyl group here, bioactivity would increase by..."
  • Basis: Model predictions + historical patterns


Layer 6: AGENT LAYER
-----------------
Agent 1: ORCHESTRATOR
  Role: Master coordinator
  Responsibilities:
    • Manage discovery workflow
    • Coordinate other agents
    • Store results and history
    • Handle user interactions
  Output: Overall strategy and decisions

Agent 2: GENERATOR
  Role: Create new candidates
  Responsibilities:
    • Generate molecules via genetic algorithm
    • Apply mutations and crossovers
    • Enforce chemical validity
    • Track genealogy
  Output: 20-50 new molecules per generation

Agent 3: PREDICTOR
  Role: Evaluate properties
  Responsibilities:
    • Compute fingerprints
    • Run ML predictions
    • Query KG for known data
    • Estimate uncertainty
  Output: Complete prediction profile

Agent 4: RANKER
  Role: Score and rank
  Responsibilities:
    • Calculate multi-objective scores
    • Rank by quality and diversity
    • Select top candidates
    • Diversify selections
  Output: Ranked candidate list

Agent 5: OPTIMIZER
  Role: Improve molecules
  Responsibilities:
    • Mutate molecules to improve scores
    • Use gradient-based optimization
    • Track improvements
    • Find local optima
  Output: Optimized molecules

Agent 6: EXPLAINER (NEW)
  Role: Generate explanations
  Responsibilities:
    • Trace reasoning paths
    • Generate mechanistic explanations
    • Provide counterfactual analysis
    • Create visualizations
  Output: Human-readable explanations


Layer 7: FEEDBACK & LEARNING LAYER
-----------------
Feedback Sources:
  1. Virtual: From ML predictions
  2. Simulated: From docking and molecular dynamics
  3. Experimental: From wet-lab validation
  4. Literature: From published results

Learning Mechanisms:
  • Reinforcement Learning: Reward signal from predictions
  • Transfer Learning: Adapt models with new data
  • Meta-Learning: Learn to learn better strategies
  • Causal Learning: Extract causal relationships

Long-term Memory:
  • All molecules tested
  • Success/failure patterns
  • Emerging strategies
  • Optimization history

Adaptation:
  • Update weights in scoring function based on success
  • Refine generation strategy based on feedback
  • Adjust model predictions with new data
  • Improve causal understanding


Layer 8: OUTPUT LAYER
-----------------
Candidates:
  • Top-ranked molecules
  • With properties and predictions
  • With mechanistic explanations
  • With uncertainty estimates

Reports:
  • Discovery history
  • Strategy effectiveness
  • Key insights learned
  • Recommended next steps

Visualizations:
  • Molecular structures (2D/3D)
  • Property landscapes
  • KG visualization
  • Reasoning paths

================================================================================
DATA FLOW ARCHITECTURE
================================================================================

Discovery Pipeline Flow:

1. INITIALIZATION
   User inputs → Orchestrator
   • Seed molecules
   • Objectives (max bioactivity, min toxicity, etc.)
   • Constraints

2. GENERATION PHASE
   Orchestrator → Generator
   • Create 20-50 new candidates
   • Track genealogy
   • Ensure diversity

3. PREDICTION PHASE
   Generator output → Predictor
   • Compute fingerprints
   • Run ML predictions
   • Query KG
   • Estimate uncertainties

4. REASONING PHASE
   Predictions + KG → Explainer
   • Generate explanations
   • Trace paths
   • Identify mechanisms

5. RANKING PHASE
   Predictions → Ranker
   • Calculate scores
   • Rank by quality
   • Select diverse top-k

6. OPTIMIZATION PHASE (Optional)
   Top candidates → Optimizer
   • Improve high-quality molecules
   • Explore local neighborhoods
   • Track improvements

7. FEEDBACK PHASE
   Results → Feedback System
   • Learn from outcomes
   • Update strategies
   • Store in memory

8. ITERATION
   Loop back to step 1 with refined strategy


Parallel Data Access:
  • All agents can query KG simultaneously
  • Predictions cached to avoid recomputation
  • Results stored in database
  • History maintained for learning

================================================================================
INTEGRATION POINTS
================================================================================

Integration with Vishwa's Dataset Work:
  ↓
  Cleaned molecules (50k+) with:
    • Canonical SMILES
    • 10+ molecular properties
    • Feature vectors
    • Graph representations
    • Train/val/test splits
  ↓
  Used for:
    • Model training
    • Feature engineering
    • Baseline predictions
    • Statistical analysis

Integration with Shreya's Knowledge Graph:
  ↓
  Knowledge graph with:
    • 50k molecules, 10k proteins
    • 200k+ relationships
    • Embeddings (256 dim)
    • Query APIs
  ↓
  Used for:
    • Similarity search
    • Mechanistic reasoning
    • Causal explanation
    • Context-aware predictions

Integration with Pranay's Architecture:
  ↓
  This document specifies:
    • Data requirements
    • Model requirements
    • Agent interfaces
    • Output specifications
    • Integration contract

================================================================================
SCALABILITY DESIGN
================================================================================

Current Scale:
  • Molecules: 50k (can grow to 1M+)
  • Proteins: 10k (can grow to 50k+)
  • Relationships: 200k (can grow to 10M+)
  • Predictions: 1-100 molecules per run

Future Scale:
  • Distributed KG across multiple databases
  • Model serving via APIs (MLflow, Seldon)
  • Parallel agent execution
  • Batch prediction (1M+ molecules)
  • Cloud deployment (AWS/Azure)

Optimization Strategies:
  • Index frequently queried KG paths
  • Cache predictions
  • Hierarchical filtering (fast→expensive)
  • Model compression for edge devices
  • Approximate inference when needed

================================================================================
SECURITY & RELIABILITY
================================================================================

Data Security:
  • Encrypted KG connections
  • Access control lists
  • Audit trails
  • Data anonymization for privacy

Model Reliability:
  • Ensemble predictions (multiple models vote)
  • Uncertainty quantification
  • Outlier detection
  • Input validation

System Reliability:
  • Error handling and recovery
  • Fallback strategies
  • Redundancy where critical
  • Health monitoring

================================================================================
TECHNOLOGY STACK
================================================================================

Core Languages:
  • Python 3.10+
  • Graph Query: Cypher (Neo4j)
  • Frontend: JavaScript/React (future)

Libraries:
  • ML: scikit-learn, TensorFlow/PyTorch
  • Chemistry: RDKit, DeepChem
  • Graphs: NetworkX, PyTorch Geometric
  • Data: Pandas, NumPy

Databases:
  • Knowledge Graph: Neo4j
  • Data Storage: PostgreSQL
  • Model Storage: MLflow artifacts
  • Cache: Redis (optional)

Infrastructure:
  • Development: Python environment (venv/conda)
  • Deployment: Docker containers
  • Orchestration: Kubernetes (future)
  • Cloud: AWS/Azure/GCP

API Frameworks:
  • Flask/FastAPI for REST APIs
  • gRPC for agent communication

================================================================================
NEXT STEPS FOR IMPLEMENTATION
================================================================================

Month 1: FOUNDATION (Current - DONE)
  ✓ Dataset preparation (Vishwa)
  ✓ KG construction (Shreya)
  ✓ Problem formulation (Pranay)
  ✓ Model training (existing agents)

Month 2: INTEGRATION
  [ ] Integrate KG with predictions
  [ ] Build explainer agent
  [ ] Implement feedback loops
  [ ] Add learning mechanisms

Month 3: VALIDATION
  [ ] Extensive testing
  [ ] Comparison with baselines
  [ ] Expert evaluation
  [ ] Literature validation

Month 4+: RESEARCH & PUBLICATION
  [ ] Real drug candidate discovery
  [ ] Wet-lab validation
  [ ] Research paper writing
  [ ] Conference presentations

================================================================================
Document Status: COMPLETE
Author: Pranay
Date Created: 2026-02-02
Last Updated: 2026-02-02
